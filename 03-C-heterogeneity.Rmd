---
layout: topic
title: "Dealing with heterogeneity"
author: Tad & Anna Rasmussen
output: html_document
---

**Assigned Reading:**

> Chapter 4 from: Zuur, A. F., Ieno, E. N., Walker, N., Saveliev, A. A. and Smith, G. M. 2009. *Mixed Effects Models and Extensions in Ecology with R.* Springer. [link](https://link-springer-com.stanford.idm.oclc.org/book/10.1007%2F978-0-387-87458-6)


```{r include = FALSE}
# This code block sets up the r session when the page is rendered to html
# include = FALSE means that it will not be included in the html document

# Write every code block to the html document 
knitr::opts_chunk$set(echo = TRUE)

# Write the results of every code block to the html document 
knitr::opts_chunk$set(eval = TRUE)

# Define the directory where images generated by knit will be saved
knitr::opts_chunk$set(fig.path = "images/03-C/")

# Set the web address where R will look for files from this repository
# Do not change this address
repo_url <- "https://raw.githubusercontent.com/fukamilab/BIO202/master/"
```

### Key Points

#### From Chapter 2
"In none of these [35] real data sets could we find a non-trivial example for a linear regression model for which all assumptions held."

#### Heterogeneity
+ One frequently violated assumption = homogeneity, i.e., that residuals are normally distributed with a mean of 0 and a fixed variace, σ2:

    + $Y_i = \alpha + \beta_1 X_{1i} + \beta_2 X_{2i} + \epsilon_i$
    + $\epsilon_i \sim N(0, \sigma^2)$

+ How to check for homogeneity
    Residuals vs. fitted values (Fig 4.2a)

+ How to identify source of variation in residuals
    Residuals vs. explanatory variables (Fig. 4.2b, c)

#### Many variance structures (Table 4.1)
  + `V1<-varFixed(∼DML)`
     + $\epsilon_i \sim N(0, \sigma^2 \times \mathrm{DML}_i) \ \ i = 1, \ldots, 768$
  + `V1<-varIdent(form= ∼ 1 | fMONTH)`
     + $\epsilon_{ij} \sim N(0, \sigma_j^{2}) \ \ j = 1, \ldots, 12$
  + `V1<-varPower(form =∼ DML)`
     + $\epsilon_{ij} \sim N(0, \sigma^2 \times |\mathrm{DML}_i|^{2\delta})$
  + `V1<-varPower(form =∼ DML | fMONTH)`
     + $\epsilon_{ij} \sim N(0, \sigma^2 \times |\mathrm{DML}_{ij}|^{2\delta_j})$
  + `V1<-varExp(form =∼ DML)`
     + $\epsilon_{ij} \sim N(0, \sigma^2 \times e^{2 \delta \times \mathrm{DML}_{ij}})$
  + `V1<-varConstPower(form =∼ DML)`
     + $\epsilon_{ij} \sim N(0, \sigma^2 \times (\delta_1 + |\mathrm{DML}_{ij}|^{\delta_2})^2)$
  + `V1<-varComb(varIdent(form =∼ 1 | fMONTH), varExp(form =∼ DML))`
     + $\epsilon_{ij} \sim N(0, \sigma^2_j \times e^{2 \delta \times \mathrm{DML}_{ij}})$

How to choose variance structure? - AIC, e.g., `AIC(M.lm, M.gls1, M.gls2)`

#### Suggested protocol
1. Fit a full model
2. Plot standardized residuals vs. each predictor
    + If variance shows a relationship with any predictor,
      re-fit model with a modified variance structure.
3. Compare models using AIC or LR test
    + If better, extract standardized residuals, plot against other factors,
      and continue to modify variance structure.
4. Remove non-significant terms from fixed effects, re-examine residual plots (iterative process)
5. Interpret


*** 

### Analysis Example

Random/explanatory variables are heterskedastic if there are sub-populations that have different variabilities from others."Variability" could be quantified by the variance or other measures of statistical dispersion.

Why is it a problem in regression??

Want models that consistantly predict response variable across different values of the explanatory variable. So if you plot residuals (the difference between modeled and actual data) the residuals should be uniform across the explanatory variable. If not, then this indicates heterogeneity/ heteroskedasticity. Modeling errors are assumed to be uncorrelated and uniform in tests so heterskedasticity is a problem.


Code and data from _Mixed Effects Models and Extensions in Ecology with R_ (2009) Zuur, Ieno, Walker, Saveliev and Smith. _Springer_ available at [highstat.com](www.highstat.com)

#### Example 1: Squid testis weight v. dorsal mantle length

Load the data, relevant code, and libraries.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# Read in files from local copies on your computer
Squid <- read.table(file = "data/Squid.txt", header = TRUE, dec=".") 
source("code/HighstatLibV10.R")

# If you do not have these files on your computer use:
Squid <- read.table("https://raw.githubusercontent.com/fukamilab/BIO202/master/data/Squid.txt", header = T)
source("https://raw.githubusercontent.com/fukamilab/BIO202/master/code/HighstatLibV10.R")
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
Squid$fMONTH=factor(Squid$MONTH)
```

A good first step is to investigate structure of the Squid data set. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
str(Squid)
```

Then, inspect residuals across explanatory variables. The variability along the explanatory variable should be consistant. Look out for cone shapes!

```{r, echo=FALSE, message=FALSE, warning=FALSE}
M1 <- lm(Testisweight ~ DML * fMONTH,data=Squid)
op <- par(mfrow = c(2,2), mar=c(4,4,2,2))
plot(M1, which=c(1), col=1, add.smooth=F, caption="")
plot(Squid$fMONTH, resid(M1), xlab="Month",
     ylab="Residuals")
plot(Squid$DML, resid(M1),xlab="DML",ylab="Residuals")
par(op)

```

Looks like we have cones, our data is hetergeneous/heteroskedastic. Now it's time to investigate variance covariates. There are several possible types of relationships between variance and covariates.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
funcs <- c("VarFixed", "VarIdent" , "VarPower" , "VarExp" , "VarConstPower" , "VarComb")
expl <- c("Fixed variance",
"Different variances per stratum", 
"Power of the variance covariate",
"Exponential of the variance covariate",
"Constant plus power of the variance covariate",
"A combination of variance functions")
tab <- cbind(funcs, expl)

kable(tab, col.names= c("R function", "Description"))
```



Let's start with a simple linear model and GLS (generalized least squares) model with fixed variance along DML (variance that is proportional to DML). 

*Note unweighted gls is just a lm

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(nlme)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
M.lm<-gls(Testisweight~DML*fMONTH,data=Squid)
vf1Fixed<-varFixed(~DML)
M.gls1<-gls(Testisweight~DML*fMONTH,
              weights=vf1Fixed,data=Squid)
anova(M.lm,M.gls1)

```

Now allow for different variance for each month

```{r, echo=TRUE, message=FALSE, warning=FALSE}
vf2 <- varIdent(form= ~ 1|fMONTH)
M.gls2 <- gls(Testisweight ~ DML*fMONTH,
              weights=vf2, data =Squid)
anova(M.lm,M.gls1,M.gls2)

```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
anova(M.lm,M.gls2)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
summary(M.gls2)
```

Let's look at the residuals across months to further investigate. Graphs yay!

```{r, message=FALSE, warning=FALSE}
library(lattice)

E <- resid(M.lm)
coplot(E~DML|fMONTH,data=Squid)
```

Now, let's look at all the different types of variance-covariate relationships

```{r, echo=TRUE, message=FALSE, warning=FALSE}
vf3 <- varPower(form =~ DML)
M.gls3 <- gls(Testisweight ~ DML * fMONTH,
              weights = vf3,data=Squid)

vf4 <- varPower(form=~ DML | fMONTH)
M.gls4<-gls(Testisweight ~ DML * fMONTH, data = Squid,
              weights = vf4)


vf5 <- varExp(form =~ DML)
M.gls5 <- gls(Testisweight ~ DML * fMONTH,
              weights = vf5, data = Squid)


vf6<-varConstPower(form =~ DML)
M.gls6<-gls(Testisweight ~ DML * fMONTH,
            weights = vf6, data = Squid)


vf7 <- varConstPower(form =~ DML | fMONTH)
M.gls7<-gls(Testisweight ~ DML * fMONTH,
              weights = vf7, data = Squid)

vf8 <- varComb(varIdent(form= ~ 1 | fMONTH) ,
                 varExp(form =~ DML) )
M.gls8<-gls(Testisweight ~ DML * fMONTH,
              weights = vf8, data = Squid)

anova(M.lm,M.gls1,M.gls2,M.gls3,M.gls4,
        M.gls5,M.gls6,M.gls7,M.gls8)

```

Ooh la la looks like varPower(form=~ DML | fMONTH) is the best model

```{r, echo=TRUE, message=FALSE, warning=FALSE}
anova(M.lm,M.gls4)

```

Let's graphically confirm.

First look at ordinary residuals 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
E1 <- resid(M.gls4)
coplot(E1 ~ DML | fMONTH,ylab="Ordinary residuals",
      data = Squid)
```

Turns out we should actually look at normalized residuals for model validation. Calculate the observed minus the fitted values and then divide by the square root of the variance. There shouldn't be any heteroskedasticity.

```{r, echo=TRUE, message=FALSE, warning=FALSE}


E2 <- resid(M.gls4, type = "normalized")
coplot(E2 ~ DML | fMONTH, data = Squid,
       ylab = "Normalised residuals")


anova(M.gls4)

```


Some notes for picking var functions from the book: 

+ If the variance covariate is a nominal variable use varIdent.
+ varFixed assumes that the variance of the residuals is linearly related to a variance covariate. 
+ varPower should not be used if the variance covariate takes the value of zero. 


If you want more!

#### Second example: Benthic Biodiversity in nutrient amended tanks

```{r, echo=TRUE, message=FALSE, warning=FALSE}
Biodiversity <- read.table(file = "data/Biodiversity.txt", header = TRUE, dec=",") 
source("code/HighstatLibV10.R")

library(nlme)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
Biodiv <- Biodiversity #saves some space
Biodiv$fTreatment <- factor(Biodiv$Treatment)
Biodiv$fNutrient  <- factor(Biodiv$Nutrient)
Biodiv$Concentration <- as.numeric(levels(Biodiv$Concentration))[Biodiv$Concentration]
Biodiv$Biomass  <- as.numeric(levels(Biodiv$Biomass))[Biodiv$Biomass]
str(Biodiv)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
boxplot(Concentration~(Treatment)*factor(Nutrient),data=Biodiv)
M0<-lm(Concentration~Biomass*factor(Treatment)*factor(Nutrient),data=Biodiv)
plot(M0,which=c(1),add.smooth=FALSE)

```

**Create several models with different variance covariates**

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(nlme)

M0<-gls(Concentration~Biomass*fTreatment*fNutrient, ## linear model without any variance covariates
      data = Biodiv)
M1A<-gls(Concentration~Biomass*fTreatment*
    fNutrient,weights=varIdent(
    form=~1|fTreatment*fNutrient),
    data = Biodiv) ## just one variance covariate per nutrient enrichment combination
M1B<-gls(Concentration~Biomass*fTreatment*
    fNutrient,
    weights=varIdent(form=~1|fNutrient),
    data=Biodiv) ## Nutrient covariates
M1C<-gls(Concentration~Biomass*fTreatment*
    fNutrient,
    weights=varIdent(form=~1|fTreatment),
    data = Biodiv) ## Enrichment covariates


anova(M0,M1A,M1B,M1C)
```

Looks like `varIdent` is best because nominal variables are important

```{r, echo=TRUE, message=FALSE, warning=FALSE}
anova(M1A)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
summary(M1A)
```

**Drop the three-way interaction term**

```{r, echo=TRUE, message=FALSE, warning=FALSE}

M2A1<-gls(Concentration ~ Biomass + fTreatment +
           fNutrient +
           Biomass:fTreatment +
           Biomass:fNutrient +
           fTreatment:fNutrient +
           Biomass:fTreatment:fNutrient,
           weights = varIdent(form =~ 1 | fTreatment *
                                         fNutrient),
           method = "ML", data = Biodiv)

M2A2<-gls(Concentration ~ Biomass + fTreatment +
           Nutrient +
           Biomass:fTreatment +
           Biomass:fNutrient +
           fTreatment:fNutrient,
           weights=varIdent(form =~ 1 |
                                      fTreatment*
                                      fNutrient),
          method="ML", data = Biodiv)

anova(M2A1,M2A2)
```

**Next, assess the significance of all three of the two-way interactions using ANOVAs**

_Drop Biomass:Treatment_
```{r, echo=FALSE, message=FALSE, warning=FALSE}
vfOptim<-varIdent(form=~1|fTreatment*fNutrient)

#Full model
M3.Full<-gls(Concentration~Biomass+fTreatment+fNutrient+
          Biomass:fTreatment+
          Biomass:fNutrient+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)
          

#Drop Biomass:fTreatment
M3.Drop1<-gls(Concentration~Biomass+fTreatment+fNutrient+
          Biomass:fNutrient+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)
anova(M3.Full,M3.Drop1)
```

_Drop Biomass:Nutrient_
```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Drop Biomass:fNutrient
M3.Drop2<-gls(Concentration~Biomass+fTreatment+fNutrient+
          Biomass:fTreatment+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)
anova(M3.Full,M3.Drop2)




```

_Drop Treatment:Nutrient_
```{r, echo=FALSE, message=FALSE, warning=FALSE}
#factor(Treatment):fNutrient
M3.Drop3<-gls(Concentration~Biomass+fTreatment+fNutrient+
          Biomass:fTreatment+
          Biomass:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)
anova(M3.Full,M3.Drop3)
```

Conclusion: drop Biomass:fTreatment

**Alternative coding**
```{r, message=FALSE, warning=FALSE, eval=FALSE}
fFull<-formula(Concentration~Biomass+fTreatment+fNutrient+
          Biomass:fTreatment+
          Biomass:fNutrient+
          fTreatment:fNutrient)
          
M3.Full<-gls(fFull,
          weights=vfOptim,
          method="ML",data=Biodiv)


#Drop Biomass:fTreatment
M3.Drop1<-update(M3.Full,.~.-Biomass:fTreatment)
anova(M3.Full,M3.Drop1)
```


```{r,message=FALSE, warning=FALSE, eval=FALSE}
#Drop Biomass:fNutrient
M3.Drop2<-update(M3.Full,.~.-Biomass:fNutrient)
anova(M3.Full,M3.Drop2)

```

```{r, message=FALSE, warning=FALSE, eval=FALSE}
#fTreatment:fNutrient
M3.Drop3<-update(M3.Full,.~.-fTreatment:fNutrient)
anova(M3.Full,M3.Drop3)

```


```{r, message=FALSE, warning=FALSE, eval=FALSE}

##Full model
M4.Full<-gls(Concentration~Biomass+fTreatment+fNutrient+
          Biomass:fNutrient+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)

#Drop Biomass:fNutrient
M4.Drop1 <- update(M4.Full, .~. -Biomass:fNutrient )
anova(M4.Full,M4.Drop1)

#Drop fTreatment:fNutrient
M4.Drop2 <- update(M4.Full, .~. -fTreatment:fNutrient )
anova(M4.Full,M4.Drop2)

```


**Continue dropping variables**

```{r, echo=TRUE, message=FALSE, warning=FALSE}

M5.Full<-gls(Concentration~Biomass+fTreatment+fNutrient+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)

#Drop fTreatment:fNutrient
M5.Drop1 <- update(M5.Full, .~. -fTreatment:fNutrient)
anova(M5.Full,M5.Drop1)
```

**Drop Biomass**

```{r, echo=TRUE, message=FALSE, warning=FALSE}

M5.Drop2 <- update(M5.Full, .~. -Biomass)
anova(M5.Full,M5.Drop2)
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#New full model
M6.Full<-gls(Concentration~fTreatment+fNutrient+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="ML",data=Biodiv)

M6.Drop1 <- update(M6.Full, .~. -fTreatment:fNutrient)
anova(M6.Full,M6.Drop1)
```

##### The aftermath

Final model after insignificant variables are dropped

```{r, echo=TRUE, message=FALSE, warning=FALSE}
MFinal<-gls(Concentration~fTreatment+fNutrient+
          fTreatment:fNutrient,
          weights=vfOptim,
          method="REML",data=Biodiv)


E<-resid(MFinal,type="normalized")
Fit=fitted(MFinal)

op<-par(mfrow=c(1,2))
plot(x=Fit,y=E,xlab="Fitted values",ylab="Residuals",
main="Residuals versus fitted values")
#identify(Fit,E)
hist(E,nclass=15)
par(op)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
summary(MFinal)
```

Explore findings graphically 

```{r, echo=FALSE, message=FALSE, warning=FALSE}

boxplot(E~fTreatment*fNutrient,data=Biodiv)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
PV=predict(MFinal)

boxplot(E~fTreatment*fNutrient,data=Biodiv)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
boxplot(predict(MFinal)~fTreatment*fNutrient,data=Biodiv)
```


### Discussion Questions

+ Are there other ways you deal with heterskedasticity/heterogeneity in regressions?
+ Are there faster methods for eliminating interactions and variables than shown in the text? What if you have a lot of random/explanatory variables?
+ Are there other types of heterskedasticity you deal with in your data?



