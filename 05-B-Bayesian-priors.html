<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jes &amp; Nicole" />


<title>Bayesian Inference with Prior Information</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="00-computer-setup.html">Computer Setup</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W1
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01-A-R-intro.html">Intro to R</a>
    </li>
    <li>
      <a href="01-B-Rmarkdown-intro.html">R markdown</a>
    </li>
    <li>
      <a href="01-C-R-workshop.html">R workshop</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W2
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="02-A-tidyr.html">ggplot2 and tidyr</a>
    </li>
    <li>
      <a href="02-B-git-intro.html">Intro to git</a>
    </li>
    <li>
      <a href="02-C-student-projects.html">Project introductions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W3
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03-A-data-exploration.html">Data exploration</a>
    </li>
    <li>
      <a href="03-B-linear-models.html">Linear models</a>
    </li>
    <li>
      <a href="03-C-heterogeneity.html">Heterogeneity</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W4
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="04-A-mixed-models.html">Mixed effects models</a>
    </li>
    <li>
      <a href="04-B-binary-data.html">Binary &amp; proportional data</a>
    </li>
    <li>
      <a href="04-C-zero-data.html">Zero-inflated data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W5
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="05-A-Bayesian-linear-models.html">Bayesian linear models</a>
    </li>
    <li>
      <a href="05-B-Bayesian-priors.html">Bayesian inference with prior information</a>
    </li>
    <li>
      <a href="05-C-Advanced-bayesian-example.html">Advanced Bayesian model example</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W6
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06-A-unconstrained-ordination.html">Unconstrained ordination</a>
    </li>
    <li>
      <a href="06-B-constrained-ordination.html">Constrained ordination</a>
    </li>
    <li>
      <a href="06-C-matrix-comparison.html">Comparing multivariate data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W8
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="08-A-mapping.html">Visualizing spatial data</a>
    </li>
    <li>
      <a href="08-B-spatial-regression.html">Spatial regression</a>
    </li>
    <li>
      <a href="08-C-spatial-ordination.html">Ordination approach to spatial analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    W9
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="09-A-time-series.html">Time series</a>
    </li>
    <li>
      <a href="09-B-networks.html">Network analysis</a>
    </li>
    <li>
      <a href="09-C-occupancy-models.html">Occupancy models</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Bayesian Inference with Prior Information</h1>
<h4 class="author"><em>Jes &amp; Nicole</em></h4>

</div>


<p><strong>Assigned Reading:</strong></p>
<blockquote>
<p>Chapters 12 and 15 in Korner-Nievergelt et al. 2015. <em>Bayesian data analysis in ecology using linear models with R, BUGS, and Stan.</em> Elsevier. <a href="http://www.sciencedirect.com/science/book/9780128013700">link</a></p>
</blockquote>
<div id="key-points" class="section level3">
<h3>Key Points</h3>
<p><strong>Why use (weakly) informative priors?</strong></p>
<ul>
<li>Uniform priors are unlikely representations of our actual prior state of knowledge.</li>
<li>Supplying prior distributions with some information allows us to fit models that cannot be fit with frequentist methods. (example- all binary outcomes are the same or binary outcomes separated by a covariate)</li>
<li>Supplying prior information mirrors the scientific process.</li>
<li>Supplying prior information makes our assumptions explicit.</li>
</ul>
<p><strong>How do we fit models with non-uniform priors?</strong></p>
<ul>
<li>To fit models with non-uniform priors we need to simulate parameter samples with MCMC.</li>
<li>Mathematics proves that, given enough time, MCMC simulation methods produce samples of parameters from the joint posterior distribution.</li>
<li>Once convinced that an MCMC chain has converged to the posterior, we can use samples from it to make inferences in the same way that we used samples from <code>sim</code>, which were calculed analytically.</li>
<li>If you don’t have a lot of prior information, do a sensititivity analysis (where you change the prior distributions) to make sure that prior choice is not unduly influencing inference.</li>
</ul>
<p><strong>How do you choose prior distributions?</strong></p>
<ul>
<li>Make sure that the prior distribution covers all possible values of a parameter and doesn’t allow any values that are impossible. (E.g. <span class="math inline">\(\sigma\)</span> must be positive)</li>
<li>Read <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">this advice</a> from the Stan community.</li>
</ul>
<p><strong>How do you make inferences from MCMC output?</strong></p>
<ul>
<li>MCMC <em>converges</em> to the correct posterior distribution. Therefore initial samples are not from the distribution and we don’t want to make inference from them.
<ul>
<li>BUGS: called “burn-in”, examine trace plot of full chain and decide on cut-off.</li>
<li>Stan: called “warm-up”, not actually a Markov chain and will be automatically droped from samples if using <code>rstan</code> package.</li>
</ul></li>
<li>Markov chains are autocorrelated (adjacent values depend on one another), especially when parameters are correlated.
<ul>
<li>To get 1000 independent samples, you may need to run the chain for much longer than 1000 post-burnin iterations.</li>
<li>Can use “thinning” to avoid storing chain values that you won’t actually use (e.g. save only 1 in 10 samples).</li>
<li>Use the <em>effective sample size</em> (<code>n.eff</code>) to determine how many independent samples are possible from your chains (and run longer if necessary).</li>
<li>Here’s a paper suggests when you should and shouldn’t thin MCMC chains: <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00131.x/abstract">Link and Eaton 2011</a></li>
</ul></li>
</ul>
<p><strong>How might MCMC fail?</strong></p>
<ul>
<li>High autocorrelation within chains and correlation between parameters can cause:
<ul>
<li>Chains get stuck and don’t sample from the full posterior distribution (e.g. show bad mixing).</li>
<li>Multiple chains don’t sample from the same posterior distribution (initial starting values influence samples).</li>
</ul></li>
<li><p>Complex models (especially hierarchical models) required longer to converge.</p></li>
<li>Models will converge faster with mathematical tricks:
<ul>
<li>Center and scale predictors (<code>scale(x, center = TRUE, scale = TRUE)</code> will do: <code>(x - mean(x))/sd(x)</code>).</li>
<li>Use reparametrization to make it easier to estimate parameters, such as the variance of a random effect. See section 27, Optimizing Stan Code for Efficiency, on p. 333 in the <a href="http://mc-stan.org/users/documentation/">Stan User’s Guide and Documentation</a>.</li>
</ul></li>
<li><p>There is not enough data to estimate a parameter and the prior distribution is very vague.</p></li>
</ul>
<p><strong>How can you tell that MCMC results are reliable?</strong></p>
<ul>
<li>Trace plots that show the value of each parameter through “time” should show good “mixing”.</li>
<li>Trace plots from separate “chains” should converge on the same values.</li>
<li><span class="math inline">\(\hat{R} &lt; 1.02\)</span> shows that variance across multiple chains is the same.</li>
</ul>
<p><strong>Software comparison</strong></p>
<table>
<colgroup>
<col width="47%" />
<col width="52%" />
</colgroup>
<thead>
<tr class="header">
<th>OpenBUGS (also WinBUGS, JAGS)</th>
<th>Stan</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Older = more textbook and tutorial examples.</td>
<td>Newer = more active development.</td>
</tr>
<tr class="even">
<td>Uses Gibbs sampling, Metropolis-Hastings algoritm or slice sampling.</td>
<td>Uses Hamiltonian Monte Carlo sampling and optimization-based point estimation.</td>
</tr>
<tr class="odd">
<td>Some details can be implicit.</td>
<td>All model details must be explicit.</td>
</tr>
<tr class="even">
<td>Slower computation.</td>
<td>Faster computation, especially for hierarchical models and large data sets.</td>
</tr>
<tr class="odd">
<td>Limited number of functions available.</td>
<td>Many functions avaible.</td>
</tr>
<tr class="even">
<td>Write models using loops.</td>
<td>Write models using loops or vector algebra.</td>
</tr>
<tr class="odd">
<td>Can only provide data used to fit the model.</td>
<td>Can provide extraneous data.</td>
</tr>
<tr class="even">
<td>Must provide initial values.</td>
<td>Initial values optional.</td>
</tr>
<tr class="odd">
<td>Chains more autocorrelated.</td>
<td>Chains less autocorrelated.</td>
</tr>
<tr class="even">
<td>Detailed <a href="http://www.openbugs.net/w/Documentation">documentation and examples</a></td>
<td>Detailed <a href="http://mc-stan.org/users/documentation/index.html">documentation and examples</a>.</td>
</tr>
</tbody>
</table>
<p><strong>Steps:</strong></p>
<ol start="0" style="list-style-type: decimal">
<li>Install <a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">Stan</a> or <a href="http://www.openbugs.net/w/Downloads">OpenBUGS</a> or <a href="http://mcmc-jags.sourceforge.net/">JAGS</a></li>
<li>Write down the model(s) you want to fit on paper.</li>
<li>Specify prior distributions for all unknown parameters.</li>
<li>Convert the model(s) to Stan (or BUGS) code in a text file.</li>
<li>Create R objects containing the data needed to fit the model(s).</li>
<li>Use <code>rstan</code> or <code>R2OpenBUGS</code> or <code>R2jags</code> (or other package) to fit the models in R by referencing the model text file.</li>
<li>Examine trace plots, <span class="math inline">\(\hat{R}\)</span> and effective samples sizes for each parameter.</li>
<li>Examine correlations between parameters.</li>
<li>Decide whether chains are sampling from the posterior distribution.</li>
<li>Check whether priors are unduly influencing posterior.</li>
<li>Proceed with model selection and validation by examining information criteria (WAIC) and residuals. Repeat steps 1-10 as needed to find an acceptable model.</li>
<li>Use samples from final model after the burn-in period to make inferences.</li>
</ol>
<p><strong>R Tools</strong></p>
<ul>
<li>The <code>coda</code> package is frequently used to visualize MCMC results.</li>
<li>Check out the <code>ggmcmc</code> package for plotting MCMC results with <code>ggplot2</code>: <a href="http://xavier-fim.net/packages/ggmcmc/">website</a></li>
</ul>
<p><br></p>
</div>
<div id="analysis-example" class="section level3">
<h3>Analysis Example</h3>
<p>In this analysis example, we’re going to build on the material covered in the last seminar <a href="https://fukamilab.github.io/BIO202/05-A-Bayesian-linear-models.html">Bayesian Inference from Linear Models</a>. This will enable us to see the similarities and focus more on the differences between the two approaches: (1) using uniform prior distributions (i.e., flat priors or “noninformative” priors), and (2) using non-uniform prior distributions (i.e., informative priors) to perform Bayesian inference.</p>
<p>We will use the same dataset as before (Appendix A in Zuur et al. 2009. <em>Mixed Effects Models and Extensions in Ecology with R</em>). Again, we’re are going to look at how density of birds in a forest patch (continuous response variable = ABUND) differs by the mean altitude of a patch (continuous explanatory variable = ALT). <strong>However, this time we will apply prior distributions containing “prior knowledge” about the parameters used in our model.</strong></p>
<p>The art of choosing prior distributions (or “priors”) is covered in Chapter 15 in Korner-Nievergelt et al. 2015. <em>Bayesian data analysis in ecology using linear models with R, BUGS, and Stan.</em> Most of the code is borrowed from section 12.3 (MCMC using Stan) in the same book.</p>
<p><br></p>
<div id="step-1-the-model" class="section level4">
<h4>Step 1: The model</h4>
<p>Again, the dataset we’re going to use is shown below (but we’re only interested in the variables ABUND and ALT).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load dataset</span>
Loyn &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/Loyn.txt&quot;</span>, <span class="dt">header=</span>T)   

<span class="co"># Show information about the dataset</span>
<span class="kw">str</span>(Loyn)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    56 obs. of  8 variables:
##  $ Site   : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ ABUND  : num  5.3 2 1.5 17.1 13.8 14.1 3.8 2.2 3.3 3 ...
##  $ AREA   : num  0.1 0.5 0.5 1 1 1 1 1 1 1 ...
##  $ DIST   : int  39 234 104 66 246 234 467 284 156 311 ...
##  $ LDIST  : int  39 234 311 66 246 285 467 1829 156 571 ...
##  $ YR.ISOL: int  1968 1920 1900 1966 1918 1965 1955 1920 1965 1900 ...
##  $ GRAZE  : int  2 5 5 3 5 3 5 5 4 5 ...
##  $ ALT    : int  160 60 140 160 140 130 90 60 130 130 ...</code></pre>
<p>Although priors could be used for more complex models, we’re going to use a similar linear model as before (with the exception of adding the priors) where <span class="math inline">\(y =\)</span> ABUND, <span class="math inline">\(x =\)</span> ALT, <span class="math inline">\(\sigma =\)</span> standard deviation, <span class="math inline">\(\beta_0 =\)</span> intercept, <span class="math inline">\(\beta_1 =\)</span> slope, <span class="math inline">\(Norm() =\)</span> normal distribution and <span class="math inline">\(Cauchy()[0,] =\)</span> truncated Cauchy distribution.</p>
<p><strong>Stochastic part</strong><br />
<span class="math inline">\(y_i \sim Norm(\hat{y_i}, \hat{\sigma} )\)</span></p>
<p><span class="math inline">\(\hat{\beta_k} \sim Norm(0, 5)\)</span></p>
<p><span class="math inline">\(\hat{\sigma} \sim Cauchy(0, 5)[0,]\)</span></p>
<p><strong>Deterministic part</strong><br />
<span class="math inline">\(\hat{y_i} = \hat{\beta_0} + \hat{\beta_1} x_i\)</span></p>
<p><br></p>
</div>
<div id="step-2-the-priors" class="section level4">
<h4>Step 2: The priors</h4>
<p>We’re going to pick prior distributions for our model parameters <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Ideally, priors should be obtained from (or based on) results from previous studies. We want to be able to merge prior knowledge with information from our given dataset. The priors should be chosen so that they contain information about the range of possible values for a parameter and the plausible shape of the distribution of these values.</p>
<div id="parameter-intercept-and-slope-hatbeta_k" class="section level5">
<h5>Parameter: Intercept and slope (<span class="math inline">\(\hat{\beta_k}\)</span>)</h5>
<p>Unfortunately, I’m not that familiar with the “bird density and altitude” literature, so I don’t know what an optimal prior should look like. However, it is reasonable to assume that the intercept and the slope parameters can range from negative to positive values and that values near the endpoints (moving towards <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(\infty\)</span>) are less common. As mentioned in the book, a standard weakly informative prior for a <span class="math inline">\(\beta_k\)</span> parameter is a normal distribution with a mean at about 0 and a standard deviation of about 5, so <span class="math inline">\(Norm(\mu = 10, \sigma = 5)\)</span>. (Note: this depends on the units of our data, so we should probably do a thought experiment to decide whether the distributions shown below are reasonable for the actual values of bird density and altitude in our data.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Probability density function of the intercept and slope prior</span>
xseq &lt;-<span class="st"> </span><span class="kw">seq</span>(-<span class="dv">15</span>, <span class="dv">15</span>, <span class="fl">0.001</span>)
<span class="kw">plot</span>(xseq, <span class="kw">dnorm</span>(xseq, <span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>, <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Intercept and slope parameter prior&quot;</span>)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="parameter-sigma-hatsigma" class="section level5">
<h5>Parameter: Sigma (<span class="math inline">\(\hat{\sigma}\)</span> )</h5>
<p>Choosing a prior for variance is tricky, especially without any previous knowledge about this particular bird-altitude system. We will thus use a standard weakly informative prior using a truncated Cauchy distribution with non-negative values (as described in the book).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Probability density function of the variance (or rather standard deviation, sigma)</span>
xseq &lt;-<span class="st"> </span><span class="kw">seq</span>(-<span class="dv">15</span>, <span class="dv">15</span>, <span class="fl">0.001</span>)
<span class="kw">plot</span>(xseq, <span class="kw">dcauchy</span>(xseq, <span class="dt">location =</span> <span class="dv">0</span>, <span class="dt">scale =</span> <span class="dv">5</span>), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>, <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Sigma parameter prior&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="fl">0.55</span>,<span class="dv">15</span>))</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-4-1.png" width="672" /></p>
<p><br></p>
</div>
</div>
<div id="step-3-stan-code" class="section level4">
<h4>Step 3: Stan code</h4>
<p>Here, we are converting the model into Stan code in a separate .stan text file (e.g., mcmc.stan). There are three main blocks of code: (1) data, (2) parameters and (3) model. Comments are preceded by <code>//</code>. The sample size <code>N</code> is the only “new” object that has to be declared and we define it as a non-negative integer. The beta (<span class="math inline">\(\beta\)</span>) vector contains two elements, <code>beta[1]</code> <span class="math inline">\(= \beta_0\)</span> and <code>beta[2]</code> <span class="math inline">\(= \beta_1\)</span>, and sigma (<span class="math inline">\(\sigma\)</span>) is defined as a real continuous non-negative object.</p>
<pre><code>data {
  //Data objects declared
    int&lt;lower=0&gt; N; //Sample size for MCMC simulations
    vector[N] y; 
    vector[N] x;
}

parameters {
  //Model parameter objects declared
    vector[2] beta;
    real&lt;lower=0&gt; sigma; 
}

model {
  //Prior distributions 
    beta ~ normal(0,5);
    sigma ~ cauchy(0,5);
  //Likelihood 
    y ~ normal(beta[1] + beta[2] * x, sigma);
}</code></pre>
<p><br></p>
</div>
<div id="step-4-5-data-objects-in-r-and-mcmc-simulations-using-stan" class="section level4">
<h4>Step 4 &amp; 5: Data objects in R and MCMC simulations using Stan</h4>
<p>In a separate R script we can start by loading the R package <code>rstan</code> and defining our data objects from our dataset. Then, we run the MCMC simulations using the function <code>stan()</code>. Here, we choose to run 5 independent Markov chains for each parameter under 1000 iterations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load Stan package</span>
<span class="kw">library</span>(rstan)

<span class="co"># Declare data for Stan</span>
y &lt;-<span class="st"> </span>Loyn$ABUND
x &lt;-<span class="st"> </span>Loyn$ALT
N &lt;-<span class="st"> </span><span class="kw">nrow</span>(Loyn)
datax &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>)

<span class="co"># Run Stan</span>
mod &lt;-<span class="st"> </span><span class="kw">stan</span>(<span class="dt">file =</span> <span class="st">&quot;code/05-B.stan&quot;</span>, <span class="dt">data=</span>datax, <span class="dt">chains=</span><span class="dv">5</span>, <span class="dt">iter=</span><span class="dv">1000</span>)

<span class="co"># Save the mod object as an RData file to read in later (so you don&#39;t have to redo simulation)</span>
<span class="kw">save</span>(mod, <span class="dt">file =</span> <span class="st">&quot;data/05-B-stanmod.RData&quot;</span>)

<span class="co"># Here is another way to first compile the model before sampling from it so that you don&#39;t have to re-run the compiling</span>

<span class="co"># Read the mod object back in</span>
<span class="kw">load</span>(<span class="st">&quot;data/05-B-stanmod.RData&quot;</span>)</code></pre></div>
<p><br></p>
</div>
<div id="step-6-mcmc-analysis" class="section level4">
<h4>Step 6: MCMC analysis</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(mod, <span class="kw">c</span>(<span class="st">&quot;beta&quot;</span>, <span class="st">&quot;sigma&quot;</span>)) <span class="co"># Printing the MCMC output</span></code></pre></div>
<pre><code>## Inference for Stan model: 05-B.
## 5 chains, each with iter=1000; warmup=500; thin=1; 
## post-warmup draws per chain=500, total post-warmup draws=2500.
## 
##          mean se_mean   sd  2.5%  25%  50%   75% 97.5% n_eff Rhat
## beta[1]  2.96    0.11 3.48 -3.89 0.66 2.94  5.35  9.79   980    1
## beta[2]  0.11    0.00 0.02  0.07 0.10 0.11  0.13  0.16   979    1
## sigma   10.06    0.03 0.99  8.35 9.33 9.99 10.69 12.20  1391    1
## 
## Samples were drawn using NUTS(diag_e) at Mon Nov 06 08:08:10 2017.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>In the output above, <code>mean</code> refers to the mean of the marginal posterior distribution from the simulations for each parameter, <code>se_mean</code> refers to the the standard error of the simulations (MCMC error) since <code>se_mean = sd/n_eff</code>, and <code>sd</code> refers to the standard deviation of the marginal posterior distribution from the simulations for each parameter. The percentages are the quantiles of the posterior distribution for each parameter. Finally, <code>n_eff</code> is the effective sample size and the potential scale reduction factor, <span class="math inline">\(\hat{R}\)</span>, is basically 1, which is good since it’s supposed to be <span class="math inline">\(&lt; 1.02\)</span>. It is comparing the uncertainty (or variation) between chains with the uncertainty within a chain. <strong>Note:</strong> <code>beta[1]</code> <span class="math inline">\(= \beta_0\)</span> and <code>beta[2]</code> <span class="math inline">\(= \beta_1\)</span>.</p>
<p>To test for the unwanted non-convergence (!) we can plot traceplots (iterations against parameter sample values).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">traceplot</span>(mod, <span class="st">&quot;beta[1]&quot;</span>) </code></pre></div>
<p><img src="images/05-B/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">traceplot</span>(mod, <span class="st">&quot;beta[2]&quot;</span>) </code></pre></div>
<p><img src="images/05-B/unnamed-chunk-7-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">traceplot</span>(mod, <span class="st">&quot;sigma&quot;</span>)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-7-3.png" width="672" /></p>
<p>It seems like all 5 chains converged after about 500 iterations, so that is good. This means that we have obtained posterior distributions for our three parameters that could be used for Bayesian inference.</p>
<p>Next, lets use the <code>ggmcmc</code> R package to visualize our MCMC results a bit more.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Loading graphics packages</span>
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(ggmcmc)

<span class="co"># Save MCMC output as a ggs data frame</span>
mcmcData &lt;-<span class="st"> </span><span class="kw">ggs</span>(mod) 

<span class="kw">str</span>(mcmcData)</code></pre></div>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    7500 obs. of  4 variables:
##  $ Iteration: num  1 2 3 4 5 6 7 8 9 10 ...
##  $ Chain    : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Parameter: Factor w/ 3 levels &quot;beta[1]&quot;,&quot;beta[2]&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ value    : num  2.048 5.187 -0.871 -0.433 0.992 ...
##  - attr(*, &quot;nChains&quot;)= int 5
##  - attr(*, &quot;nParameters&quot;)= int 3
##  - attr(*, &quot;nIterations&quot;)= num 500
##  - attr(*, &quot;nBurnin&quot;)= num 500
##  - attr(*, &quot;nThin&quot;)= num 1
##  - attr(*, &quot;description&quot;)= chr &quot;05-B&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggs_histogram</span>(mcmcData)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-9-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggs_density</span>(mcmcData)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggs_traceplot</span>(mcmcData)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggs_autocorrelation</span>(mcmcData)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-12-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggs_crosscorrelation</span>(mcmcData)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-13-1.png" width="672" /></p>
<p>More functions for performing MCMC posterior distribution analysis can be found <a href="http://xavier-fim.net/packages/ggmcmc/">here</a>.</p>
<p><br></p>
</div>
<div id="step-7-extracting-mcmc-results-and-testing-for-parameter-correlations" class="section level4">
<h4>Step 7: Extracting MCMC results and testing for parameter correlations</h4>
<p>If parameters are correlated then MCMC can fail as explained in the Key Points section.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Extracting our parameters from the MCMC output and save it as a new data frame</span>
modSims &lt;-<span class="st"> </span>rstan::<span class="kw">extract</span>(mod) 

<span class="kw">str</span>(modSims)</code></pre></div>
<pre><code>## List of 3
##  $ beta : num [1:2500, 1:2] 1.82 1.32 -2.05 4.97 1.93 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ iterations: NULL
##   .. ..$           : NULL
##  $ sigma: num [1:2500(1d)] 8.47 11.16 9.81 10.65 10.05 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 1
##   .. ..$ iterations: NULL
##  $ lp__ : num [1:2500(1d)] -157 -157 -157 -156 -156 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 1
##   .. ..$ iterations: NULL</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Scatter plots of parameters to look for correlations</span>
<span class="kw">plot</span>(modSims$beta[,<span class="dv">1</span>], modSims$beta[,<span class="dv">2</span>], <span class="dt">xlab=</span><span class="st">&quot;beta_0&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;beta_1&quot;</span>)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-15-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(modSims$beta[,<span class="dv">1</span>], modSims$sigma, <span class="dt">xlab=</span><span class="st">&quot;beta_0&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;sigma&quot;</span>)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-15-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(modSims$beta[,<span class="dv">2</span>], modSims$sigma, <span class="dt">xlab=</span><span class="st">&quot;beta_1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;sigma&quot;</span>)</code></pre></div>
<p><img src="images/05-B/unnamed-chunk-15-3.png" width="672" /></p>
<p>There seems to be a correlation between the intercept parameter <span class="math inline">\(\beta_0\)</span> and the slope parameter <span class="math inline">\(\beta_1\)</span>. This is not ideal, and there are ways to deal with this issue (this will be discussed in <a href="https://fukamilab.github.io/BIO202/05-C-Advanced-bayesian-example.html">Advanced Bayesian model example</a>). Thankfully, the <span class="math inline">\(\sigma\)</span> parameter does not correlate with any of the other parameters.</p>
<p>Normally, we would perform a prior sensitity analysis to see whether the posterior distributions are influenced by the defined prior distributions and maybe modify our priors accordingly until we are fully satisfied with our model (and repeating steps 1-7).</p>
<p><br></p>
</div>
<div id="step-8-inference" class="section level4">
<h4>Step 8: Inference</h4>
<p>Now that we have our joint posterior distribution <span class="math inline">\(p(\theta | y)\)</span> we can perform Bayesian inference much like in the previous seminar session (based on similar code).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newData &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="kw">min</span>(Loyn$ALT), <span class="kw">max</span>(Loyn$ALT), <span class="dt">by=</span><span class="fl">0.1</span>)) 

newMatrix &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(~x, newData)

b &lt;-<span class="st"> </span><span class="kw">apply</span>(modSims$beta, <span class="dv">2</span>, mean)
newData$mod &lt;-<span class="st"> </span>newMatrix %*%<span class="st"> </span>b
nsim &lt;-<span class="st"> </span><span class="kw">nrow</span>(modSims$beta)

fitmat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol=</span>nsim, <span class="dt">nrow=</span><span class="kw">nrow</span>(newData)) 
for(i in <span class="dv">1</span>:nsim){
  fitmat[,i] &lt;-<span class="st"> </span>newMatrix %*%<span class="st"> </span>modSims$beta[i,] 
}

<span class="co"># 95% CrI lines</span>
newData$fitupper &lt;-<span class="st"> </span><span class="kw">apply</span>(fitmat, <span class="dv">1</span>, quantile, <span class="dt">prob=</span><span class="fl">0.975</span>)
newData$fitlower &lt;-<span class="st"> </span><span class="kw">apply</span>(fitmat, <span class="dv">1</span>, quantile, <span class="dt">prob=</span><span class="fl">0.025</span>) 

<span class="co"># Linear regression</span>
linearModel &lt;-<span class="st"> </span><span class="kw">lm</span>(ABUND ~<span class="st"> </span>ALT, Loyn) 

<span class="kw">plot</span>(Loyn$ALT,Loyn$ABUND, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">cex.lab=</span><span class="fl">1.2</span>, <span class="dt">xlab=</span><span class="st">&quot;Mean altitude of a patch&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Density of birds in a patch&quot;</span>)
<span class="kw">abline</span>(linearModel, <span class="dt">lw=</span><span class="dv">2</span>) <span class="co"># Linear regression line</span>
<span class="kw">lines</span>(newData$x, newData$fitupper, <span class="dt">lty=</span><span class="dv">3</span>)
<span class="kw">lines</span>(newData$x, newData$fitlower, <span class="dt">lty=</span><span class="dv">3</span>) </code></pre></div>
<p><img src="images/05-B/unnamed-chunk-16-1.png" width="672" /></p>
<p>The regression line (solid) is supposed to act as a reference for the 95% CrI (dashed lines) obtained with prior information when comparing it with the CrI obtained with uniform priors in the previous seminar. The results using non-uniform priors differ only slightly, as expected.</p>
</div>
</div>
<div id="discussion-questions" class="section level3">
<h3>Discussion Questions</h3>
<ul>
<li>Why is the <span class="math inline">\(\hat{R}\)</span> threshold set at 1.02 (or less strictly at 1.1)?</li>
<li>How can mixing or homogenous sampling be discerned in the traceplots?</li>
<li>What’s the golden rule when it comes to choosing optimal priors? They should not be (1) too strong, so that they are not providing us with additional information (not found in the dataset - too much overlap between prior and posterior), but also not too weak (2) to not influence the results due to lack of prior knowledge. Is there a better way than exploring different options via trail and error?</li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
